#DBN
深度信念网络DBN;			通过概率大小学习的神经网络
把RBM堆叠在一块，然后形成一大串连接的RBM，最后在顶端加入一个输出层

1. 把原始数据输入到最下面的RBM可视层中，然后训练RBM1，训练完成之后把RBM1的隐含层作为RBM2的可视层，继续训练RBM2，接下来把RBM2的隐含层做为RBM3的可视层，直到训练完成为止。
RBM的最后一隐含层层与输出层连接
2. 反向传播


##训练模型:

1. 预训练：分别单独无监督地训练每一层 RBM 网络,确保特征向量映射到不同特征空间时,都尽可能多地保留特征信息;

2. 微调：在 DBN 的最后一层设置 BP 网络,接收 RBM 的输出特征向量作为它的输入特征向量,有监督地训练实体关系分类器.

每一层 RBM 网络只能确保自身层内的 权值对该层特征向量映射达到最优,并不是对整个 DBN 的特征向量映射达到最优,所以反向传播网络还将错误信息自顶向下传播至每一层 RBM

3. 微调整个 DBN 网络.

总结：
		RBM 网络训练模型的过程可以看作对一个深层 BP 网络权值参数的初始化,
		使DBN 克服了 BP 网络因随机初始化权值参数而容易陷入局部最优和训练时间长的缺点.
		#DBN

##具体步骤

1. 首先充分训练第一个 RBM；
2. 固定第一个 RBM 的权重和偏移量，然后使用其隐性神经元的状态，作为第二个 RBM 的输入向量；
3. 充分训练第二个 RBM 后，将第二个 RBM 堆叠在第一个 RBM 的上方；
4. 重复以上三个步骤任意多次；
5. 如果训练集中的数据有标签，那么在顶层的 RBM 训练时，这个 RBM 的显层中除了显性神经元，还需要有代表分类标签的神经元，一起进行训练：
a) 假设顶层 RBM 的显层有 500 个显性神经元，训练数据的分类一共分成了 10 类
b) 那么顶层 RBM 的显层有 510 个显性神经元，对每一训练训练数据，相应的标签神经元被打开设为 1，而其他的则被关闭设为 0。

##调优过程 (Fine-Tuning) ：
生成模型使用 Contrastive Wake-Sleep 算法进行调优，其算法过程是：

1. 除了顶层 RBM，其他层 RBM 的权重被分成向上的认知权重和向下的生成权重；
2. Wake 阶段：认知过程，通过外界的特征和向上的权重 (认知权重) 产生每一层的抽象表示 (结点状态) ，并且使用梯度下降修改层间的下行权重 (生成权重) 。也就是“如果现实跟我想象的不一样，改变我的权重使得我想象的东西就是这样的”。
3. Sleep 阶段：生成过程，通过顶层表示 (醒时学得的概念) 和向下权重，生成底层的状态，同时修改层间向上的权重。也就是“如果梦中的景象不是我脑中的相应概念，改变我的认知权重使得这种景象在我看来就是这个概念”。
