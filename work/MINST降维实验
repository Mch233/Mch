##MINST降维实验：

本次是训练4个隐含层的autoencoder深度网络结构
输入层维度为784维，4个隐含层维度分别为1000,500,250,30。
整个网络权值的获得流程梳理如下：

1. 首先训练第一个rbm网络，即输入层784维和第一个隐含层1000维构成的网络。
采用的方法是rbm优化，这个过程用的是训练样本，优化完毕后，计算训练样本在隐含层的输出值。
2.利用1中的结果作为第2个rbm网络训练的输入值，同样用rbm网络来优化第2个rbm网络，并计算出网络的输出值。
并且用同样的方法训练第3个rbm网络和第4个rbm网络。
3.将上面4个rbm网络展开连接成新的网络，且分成encoder和decoder部分。并用步骤1和2得到的网络值给这个新网络赋初值。
4.由于新网络中最后的输出和最初的输入节点数是相同的，所以可以将最初的输入值作为网络理论的输出标签值，
然后采用BP算法计算网络的代价函数和代价函数的偏导数。
5.利用步骤3的初始值和步骤4的代价值和偏导值，采用共轭梯度下降法优化整个新网络，得到最终的网络权值。
以上整个过程都是无监督的。

RBM权值的优化步骤
1.随机给网络初始化一个权值矩阵w和偏置向量b。
2.对可视层输入矩阵v正向传播，计算出隐含层的输出矩阵h，并计算出输入v和h对应节点乘积的均值矩阵
3.此时2中的输出h为概率值，将它随机01化为二值变量。
4.利用3中01化了的h方向传播计算出可视层的矩阵v’.(按照道理，这个v'应该是要01化的)
5.对v’进行正向传播计算出隐含层的矩阵h’，并计算出v’和h’对应节点乘积的均值矩阵。
6.用2中得到的均值矩阵减掉5中得到的均值矩阵，其结果作为对应权值增量的矩阵。
7.结合其对应的学习率，利用权值迭代公式对权值进行迭代。
重复计算2到7，直至收敛。

偏置值的优化步骤：
1.随机给网络初始化一个权值矩阵w和偏置向量b。
2.对可视层输入矩阵v正向传播，计算出隐含层的输出矩阵h，并计算v层样本的均值向量以及h层的均值向量。
3.此时2中的输出h为概率值，将它随机01化为二值变量。
4.利用3中01化了的h方向传播计算出可视层的矩阵v’.
5.对v’进行正向传播计算出隐含层的矩阵h’， 并计算v‘层样本的均值向量以及h’层的均值向量。
6.用2中得到的v方均值向量减掉5中得到的v’方的均值向量，其结果作为输入层v对应偏置的增值向量。
用2中得到的h方均值向量减掉5中得到的h’方的均值向量，其结果作为输入层h对应偏置的增值向量。
7.结合其对应的学习率，利用权值迭代公式对偏置值进行迭代。
8.重复计算2到7，直至收敛。
